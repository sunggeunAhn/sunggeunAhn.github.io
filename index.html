<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Sunggeun Ahn, Human Computer Interaction
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-146052-15', 'getpoole.com');
    ga('send', 'pageview');
  </script>


  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
.fa {
  padding: 10px;
  font-size: 15px;
  width: 15px;
  text-align: center;
  text-decoration: none;
  margin: 2px 1px;
  border-radius: 50%;
}

.fa-google {
  background: #dd4b39;
  color: white;
}

.fa-linkedin {
  background: #007bb5;
  color: white;
}

</style>
</head>


  <body>

<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
          Sunggeun Ahn
      </h1>
      <p class="lead">Software Engineer & Interaction Designer, who interested in how people interact in XR environments</p>
      <p>Ph.D. in Computer Science
      </br><strong><a href="https://hcil.kaist.ac.kr/">HCI Lab @ School of Computing, KAIST</a></strong></p>
      <hr>
      </br>Contact: sunggeunAhn.hci@google.com

       <a href="https://www.linkedin.com/in/sunggeun-ahn-hcil" class="fa fa-linkedin"></a>
       <a href="https://scholar.google.com/citations?user=cjIKn4QAAAAJ&hl=ko" class="fa fa-google"></a>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Curriculum Vitae</a>
      <a class="sidebar-nav-item" Project (TBU)
    </nav>

  </div>
</div>


<div class="content container">
  <div class="posts">
     <div class="post">

<h1 class="post-title"><a href="/">Curriculum Vitae</a></h1>

<span class="post-date">17 Dec 2022</span>
<p>My research aims to make digital information space more accessible by designing effective human-computer interaction techniques. This means making it easy for people to achieve and manipulate information whenever and wherever. To make a whenever and wherever accessible interface, my researches mostly focus on designing an interface for mobile and wearable computing devices. My recent interest especially lies at utilizing gaze input modality to use rich contextual information which reflects on the user's eye gaze behavior.</p>


<h3 id="education">Education</h3>

<blockquote>
<p>Korea Advanced Institute of Science and Technology (KAIST) | <em>Daejeon, South Korea</em>
</br><strong>Ph.D. in Computer Science</strong>, <em>Advisor</em>: Geehyuk Lee
</br>Mar. 2016 ~ Feb. 2022
</br>
</br></p>

<p>Korea Advanced Institute of Science and Technology (KAIST)  |  <em>Daejeon, South Korea</em>
</br><strong>M.S. in Computer Science</strong>. <em>Advisor</em>: Geehyuk Lee
</br><em>Thesis</em>: &ldquo;FourSides: an interaction technique utilizing the four sides of a smartwatch&rdquo; <strong>[J.1]</strong>
</br>Mar. 2014 ~ Feb. 2016
</br>
</br></p>

<p>Kyungpook National University (KNU)  |  <em>Daegu, South Korea</em>
</br><strong>B.S. in Electronics Engineering</strong> (Major), <strong>Computer Science</strong> (minor), and <strong>Psychology</strong> (minor).<br />
Mar. 2007 ~ Feb. 2014
</br></p>
</blockquote>


<h3 id="peer-reviewed-publications">Peer-reviewed Publications</h3>
<p><strong><font color="FF5733">7 </font></strong> Conference papers and <strong><font color="FF5733">1</font></strong> Journal paper, <a href="https://scholar.google.com/citations?user=cjIKn4QAAAAJ&amp;hl=en">Google Scholar</a></p>

<ul>
<li><p><strong>[C.7]</strong> Taejun Kim, Auejin Ham, <strong>Sunggeun Ahn</strong>, and Geehyuk Lee <strong><a href="https://dl.acm.org/doi/10.1145/3491102.3501977">Lattice Menu: A Low-Error Gaze-Based Marking Menu Utilizing Target-Assisted Gaze Gestures on a Lattice of Visual Anchors</a></strong>, CHI22</br>(<em>Acceptance Rate: 26.1%</em>), 11 pages.
</br></p></li>

<li><p><strong>[C.6]</strong> <strong>Sunggeun Ahn</strong>, Stephanie Santosa, Mark Parent, Daniel Wigdor, Tovi Grossman, and Marcello Giordano, <strong><a href="https://dl.acm.org/doi/10.1145/3411764.3445297">StickyPie: A Gaze-Based, Scale-Invariant Marking Menu Optimized for AR/VR</a></strong>, CHI21
</br>(<em>Acceptance Rate: 26.3%</em>), 16 pages.
</br></p></li>

<li><p><strong>[C.5]</strong> <strong>Sunggeun Ahn</strong> and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=3347883">Gaze-Assisted Typing for Smart Glasses</a></strong>, UIST&rsquo;19.
</br>(<em>Acceptance Rate: 24.4%</em>), 13 pages.
</br></p></li>

<li><p><strong>[C.4]</strong> Sunbum Kim, <strong>Sunggeun Ahn</strong>, and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=3279792">DiaQwerty: QWERTY Variants to Better Utilize the Screen Area of a Round or Square Smartwatch</a>,</strong> ISS&rsquo;18.
</br>*<em>Acceptance Rate: 26.7%</em>, 7 pages.
</br></p></li>

<li><p><strong>[C.3]</strong> Jingun Jung, Sangyoon Lee, <strong>Sunggeun Ahn</strong>, and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=3229471">Auto-switching List Search Interface for Touchscreen Smartwatches</a>,</strong> mobileHCI&rsquo;18.
</br>*<em>Acceptance Rate: 24.5%</em>, 10 pages.
</br></p></li>

<li><p><strong>[J.1]</strong> <strong>Sunggeun Ahn</strong>, Jaeyeon Lee, Keunwoo Park and Geehyuk Lee. <strong><a href="https://www.sciencedirect.com/science/article/abs/pii/S1071581917301192">Evaluation of Edge-based Interaction on a Square Smartwatch</a></strong>, International Journal of Human â€“ Computer Studies 109C (2018) pp. 68-78.
</br>*<em>Impact Factor (2018)</em>: 2.006, 11 pages.
</br></p></li>

<li><p><strong>[C.2]</strong> <strong>Sunggeun Ahn</strong>, Seongkook Heo, and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=3134136">Typing on a Smartwatch for Smart Glasses</a>,</strong> ISS&rsquo;17.
</br>*<em>Acceptance Rate: 26.9%</em>, 9 pages.
</br></p></li>

<li><p><strong>[C.1]</strong> Jaehyun Han, <strong>Sunggeun Ahn</strong>, Keunwoo Park, and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=3134134">Designing Multi-Touch Gestures Using the Space around the Smartwatch as Continuous Input Space</a></strong>, ISS&rsquo;17.
</br>*<em>Acceptance Rate: 26.9%</em>, 10 pages.
</br></p></li>

</ul>


<h3 id="posters-and-demos">Posters and Demos</h2>
<ul>
<p><strong><font color="FF5733">5</font></strong> Posters and <strong><font color="FF5733">2</font></strong> Demos</p>

<li><p><strong>[P.5]</strong> Jeongmin Son, <strong>Sunggeun Ahn</strong>, Sunbum Kim and Geehyuk Lee. <strong><a href="https://dl.acm.org/doi/abs/10.1145/3491101.3519794">Effect of Contact Points Feedback on Two-Thumb Touch Typing in Virtual Reality</a></strong>, CHI&rsquo;22 Late-Breaking Work. 
</br></p></li>

<li><p><strong>[P.4]</strong> <strong>Sunggeun Ahn</strong>, Jeongmin Son, Sangyoon Lee and Geehyuk Lee. <strong><a href="https://dl.acm.org/doi/abs/10.1145/3334480.3382908">Verge-it: Gaze Interaction for a Binocular Head-Worn Display using Modulated Disparity Vergence Eye Movement</a></strong>, CHI&rsquo;20 Late-Breaking Work. 
</br></p></li>

<li><p><strong>[D.2]</strong> <strong>Sunggeun Ahn</strong> and Geehyuk Lee. <strong>Gaze-Assisted Typing for Smart Glasses</strong>, UIST&rsquo;19 Demo for [C.5]
</br></p></li>

<li><p><strong>[P.3]</strong> Jeongmin Son, <strong>Sunggeun Ahn</strong>, Sunbum Kim and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=3312926">Improving Two-Thumb Touchpad Typing in Virtual Reality</a>,</strong> CHI&rsquo;19 Late-Breaking Work.
</br></p></li>

<li><p><strong>[D.1]</strong> <strong>Sunggeun Ahn</strong>, Seongkook Heo, and Geehyuk Lee. <strong>Typing on a Smartwatch for Smart Glasses,</strong> ISS&rsquo;17 Demo for [C.2]
</br></p></li>

<li><p><strong>[P.2]</strong> Jaehyun Han, <strong>Sunggeun Ahn</strong>, and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=2732849">Transture: Continuing a Touch Gesture on a Small Screen into the Air</a></strong>, CHI&rsquo;15 Work-In-Progress
</br></p></li>

<li><p><strong>[P.1]</strong> Jaehyun Han, <strong>Sunggeun Ahn</strong>, and Geehyuk Lee. <strong><a href="https://dl.acm.org/citation.cfm?id=2658797">Push-Push: A Two-Point Touchscreen Operation Utilizing the Pressed State and the Hover State</a></strong>, UIST&rsquo;14 Adjuct.
</br></p></li>

</ul>



<h3 id="patents">Patents</h3>
<ul>
<li><p><strong>[US.3]</strong> United State Patent,  <a href="https://patents.google.com/patent/US11449138B1/en">Saccade-based positioning for radial user interface</a>, Patent#11449138, 2022-09-20
</br></p></li>

<li><p><strong>[US.2]</strong> United State Patent,  <a href="https://patents.google.com/patent/US11361540B2/en">Method and apparatus for predicting object of interest of user</a>, Patent#11361540, 2022-06-14
</br></p></li>


<li><p><strong>[KR.1]</strong> South Korea Patent, <a href="https://koasas.kaist.ac.kr/handle/10203/282355">METHOD FOR INPUT AND APPARATUSES PERFORMING THE SAME</a>, Registration#10-2237659-0000, 2021-04-02
</br></p></li>

<li><p><strong>[US.1]</strong> United State Patent,  <a href="https://patents.google.com/patent/US11023042B1/en?inventor=sunggeun+ahn&oq=sunggeun+ahn">METHOD FOR INPUTTING GAZE FOR DISPLAY AND DEVICES PERFORMING THE SAME</a>, Patent#11023042, 2021-06-01
</br></p></li>

</ul>

<h3 id="academic-services">Academic Services</h3>

<dl>
  <dt>As a committee member</dt>
  <dd>Poster track: MobileHCI19 LBR</dd>

  <dt>As a reviewer</dt>
  <dd>Paper track: MobileHCI19, ISWC19, ISS19, UIST20, VRST21, CHI20-23</dd>
  <dd>Journal: IJHCI</dd>
  <dd>Poster track: CHI LBW 18, 20, 21</dd>
</dl>


<h3 id="research-experience">Research Experience</h3>

<dl>
  <dt>Ph.D. Research Intern</dt>
  <dd><strong>Chatham Labs</strong> (Acquired by Facebook) as a research intern <strong></dd>
  <dd>May. 2020 to Sep. 2020</dd>
<blockquote>
<p><strong>Involved Project</strong>
</br>[C.6.] StickyPie: A Gaze-Based, Scale-Invariant Marking Menu Optimized for AR/VR, CHI'21
</blockquote>



  <dt>Undergraduate Research Intern</dt>
  <dd>Embedded System Platform Lab, Kyungpook National University (KNU), Prof. Jeonghun Cho. </dd>
  <dd>Feb. 2012 ~ Feb. 2014</dd>
<blockquote>
<p><strong>Involved Projects</strong>
</br>1. Vision processing project for developing Lane Detection module on ARM Cortex M3 with a camera sensor.
</br>2. Developing toolkit for mapping multiple Software Component (SWC) on a limited resourced Electronic Control Unit (ECU) on the car electronic system considering Dedicate, Exclusive, Clustering, and Separating properties of SWCs for the basic research project about AUTOSAR system.
</br>3. Investigating wireless sensor data transfer capability through Bluetooth 2.0 on the android system for mobile healthcare system.</p>
</blockquote>

</dl>


<h3 id="award">Award and Honor</h3>

<blockquote>
<p>Scholarship on an excellent grade for undergraduate students, 2013, Chungbuk Human Resource Development Foundation
</br>Samsung Exynos Young Developer Contest, Samsung Electronics, 2014 (1,000$ for the award)
</br>NAVER Ph.D. Fellowship Award, NAVER co., 2019
</blockquote>


<h3 id="skills">Skills</h3>

<blockquote>
<p><strong>Programming Language</strong>: C#, Java, Python, <font color="999999">C/C++ (Occasional) </font> 
</br><strong>Programming Tools</strong>: Visual Studio, Android Studio, PyCharm, Unity, ArduinoIDE, <font color="999999">QtCreator (Occasional)</font> 
</br><strong>Statistics/Analytic Tools</strong>: SPSS, Matlab, <font color="999999">R studio (Occasional)</font>
</br><strong>2D/3D Graphics Tools</strong>: Photoshop, <font color="999999">Illustrator (Occasional)</font>, Fusion360
</br><strong>Other Prototyping Tools</strong>: 3D printing, Laser cutting, Optitrack, Remote/Wearable Eye trackers
</br></p>
</blockquote>

<h3 id="teaching-experience">Teaching Experience</h3>

<p><strong>As a Teaching Assistant</strong></p>

<blockquote>
<p>Data Structure (CS206)
</br>Interactive Computer Graphics (CS482)
</br>Algorithms Design and Analysis (CS500)
</br>Human-Computer Interaction (CS584)
</br></p>
</blockquote>


<h3 id="non-academic-activity">Non-Academic Activity</h3>

<blockquote>
<p><strong>Military Duty</strong>: served as a police officer, Feb. 2009 ~ Dec. 2010 </br>
</blockquote>


<p><img src="http://placehold.it/800x400" alt="placeholder" title="Large example image">
<img src="http://placehold.it/400x200" alt="placeholder" title="Medium example image">
<img src="http://placehold.it/200x200" alt="placeholder" title="Small example image"></p>

  
  
     </div>
  </div>
</div>

  </body>
</html>